{
  "file_type": "PDF",
  "filename": "[google]_Agents_Companion.pdf",
  "is_machine_readable": true,
  "needs_ocr": false,
  "ocr_applied": false,
  "page_count": 76,
  "processing_time_ms": 623,
  "text": "Agents Companion \r\nAuthors: Antonio Gulli, Lavi Nigam, \r\nJulia Wiesinger, Vladimir Vuskovic, \r\nIrina Sigler, Ivan Nardini, Nicolas Stroppa,\r\nSokratis Kartakis, Narek Saribekyan, \r\nand Alan Bount\nAgents Companion\r\nFebruary 2025 2\r\nAcknowledgements\r\nEditors & curators\r\nAnant Nawalgaria\r\nContent contributors\r\nAnant Nawalgaria\r\nSteven Johnson\r\nHussain Chinoy \r\nDesigner\r\nMichael Lanning \nIntroduction 6\r\nAgent Ops 8\r\nAgent Success Metrics 12\r\nAgent Evaluation 14\r\nAssessing Agent Capabilities 15\r\nEvaluating Trajectory and Tool Use 17\r\nEvaluating the Final Response 20\r\nHuman-in-the-Loop Evaluation 21\r\nMore about Agent Evaluation 22\r\nMultiple Agents & Their Evaluation 23\r\nUnderstanding Multi-Agent Architectures 24\r\nMulti-Agent Design Patterns and Their Business Impact 25\r\nImportant components of Agents 28\r\nChallenges in Multi-Agent systems 31\r\nMulti-Agent Evaluation 32\r\nTable of contents\nAgentic RAG: A Critical Evolution in Retrieval-Augmented Generation 33\r\nAgentic RAG and its Importance 34\r\nBetter Search, Better RAG 36\r\nAgents in the enterprise 38\r\nManager of agents 38\r\nGoogle Agentspace 40\r\nNotebookLM Enterprise 41\r\nGoogle AgentSpace Enterprise 43\r\nFrom agents to contractors 46\r\nContracts 46\r\nContract Lifecycle 49\r\nContract execution 49\r\nContract Negotiation 50\r\nContract Feedback 51\r\nSubcontracts 51\r\nAutomotive AI: Real World Use of Multi-Agent Architecture 54\r\nSpecialized Agents 54\r\nConversational Navigation Agent 54\r\nConversational Media Search Agent 56\r\nMessage Composition Agent 56\r\nCar Manual Agent 57\r\nGeneral Knowledge Agent 58\r\nPatterns in Use 58\nHierarchical Pattern 58\r\nDiamond Pattern 60\r\nPeer-to-Peer 62\r\nCollaborative Pattern 64\r\nResponse Mixer Agent 66\r\nAdaptive Loop Pattern 67\r\nAdvantages of Multi-Agent Architecture for Automotive AI 68\r\nAgent Builder 69\r\nSummary 70\r\nEndnotes 74\nAgents Companion\r\nFebruary 2025 6\r\nIntroduction\r\nGenerative AI agents mark a leap forward from traditional, standalone language models, \r\noffering a dynamic approach to problem-solving and interaction. As defined in the original \r\nAgents paper, an agent is an application engineered to achieve specific objectives by \r\nperceiving its environment and strategically acting upon it using the tools at its disposal. \r\nThe fundamental principle of an agent lies in its synthesis of reasoning, logic, and access to \r\nexternal information, enabling it to perform tasks and make decisions beyond the inherent \r\ncapabilities of the underlying model. These agents possess the capacity for autonomous \r\noperation, independently pursuing their goals and proactively determining subsequent \r\nactions, often without explicit instructions.\r\nThe future of AI is agentic.\nAgents Companion\r\nFebruary 2025 7\r\nThe architecture of an agent is composed of three essential elements that drive its behavior \r\nand decision-making:\r\n‚Ä¢ Model: Within the agent's framework, the term \"model\" pertains to the language \r\nmodel (LM) that functions as the central decision-making unit, employing instruction\u0002based reasoning and logical frameworks. The model can vary from general-purpose to \r\nmultimodal or fine-tuned, depending on the agent's specific requirements.\r\n‚Ä¢ Tools: Tools are critical for bridging the divide between the agent's internal capabilities \r\nand the external world, facilitating interaction with external data and services. These \r\ntools empower agents to access and process real-world information. Tools can include \r\nextensions, functions, and data stores. Extensions bridge the gap between an API and \r\nan agent, enabling agents to seamlessly execute APIs. Functions are self-contained \r\nmodules of code that accomplish specific tasks. Data stores provide access to dynamic \r\nand up-to-date information, ensuring a model‚Äôs responses remain grounded in factuality \r\nand relevance.\r\n‚Ä¢ Orchestration layer: The orchestration layer is a cyclical process that dictates how the \r\nagent assimilates information, engages in internal reasoning, and leverages that reasoning \r\nto inform its subsequent action or decision. This layer is responsible for maintaining \r\nmemory, state, reasoning, and planning. It employs prompt engineering frameworks to \r\nsteer reasoning and planning, facilitating more effective interaction with the environment \r\nand task completion. Reasoning techniques such as ReAct, Chain-of-Thought (CoT), and \r\nTree-of-Thoughts (ToT) can be applied within this layer.\r\nBuilding on these foundational concepts, this companion paper is designed for developers \r\nand serves as a \"102\" guide to more advanced topics. It offers in-depth explorations of agent \r\nevaluation methodologies and practical applications of Google agent products for enhancing \r\nagent capabilities in solving complex, real-world problems.\nAgents Companion\r\nFebruary 2025 8\r\nWhile exploring these theoretical concepts, we'll examine how they manifest in real-world \r\nimplementations, with a particular focus on automotive AI as a compelling case study. The \r\nautomotive domain exemplifies the challenges and opportunities of multi-agent architectures \r\nin production environments. Modern vehicles demand conversational interfaces that function \r\nwith or without connectivity, balance between on-device and cloud processing for both \r\nsafety and user experience, and seamlessly coordinate specialized capabilities across \r\nnavigation, media control, messaging, and vehicle systems. Through this automotive lens, \r\nwe'll see how different coordination patterns -- hierarchical, collaborative, and peer-to\u0002peer -- come together to create robust, responsive user experiences in environments with \r\nsignificant constraints. This case study illustrates the practical application of multi-agent \r\nsystems that businesses across industries can adapt to their specific domains.\r\n Anyone who has built with gen AI quickly realizes it‚Äôs easy to get from an idea to a proof of \r\nconcept, but it can be quite difficult to ensure high quality results and get to production - gen \r\nAI agents are no exception. Quality and Reliability are the most cited concerns for deploying \r\nto production, and the ‚ÄúAgent Ops‚Äù process is a solution to optimize agent building.\r\nAgent Ops\r\nOver the past two years, the field of Generative AI (GenAI) has undergone significant \r\nchanges, with enterprise customers focusing on how to operationalize related solutions. This \r\nhas resulted in various terms describing the operationalization of GenAI, such as MLOps for \r\nGenAI, LLMOps, FMOps, and GenAIOps.\r\nAgent and Operations (AgentOps) is a subcategory of GenAIOps that focuses on the efficient \r\noperationalization of Agents. Its main additional components include internal and external \r\ntool management, agent brain prompt (goal, profile, instructions) and orchestration, memory, \r\nand task decomposition.\nAgents Companion\r\nFebruary 2025 9\r\nFigure 1. Relationship between DevOps, MLOps, and AgentOps.13\r\nEach of these ‚ÄúOps‚Äù requires capabilities like version control, automated deployments \r\nthrough CI/CD, testing, logging, security and (critically) metrics. Each system often \r\nimplements some form of optimization based on metrics ‚Äì measuring what your system \r\nis and isn‚Äôt doing, measuring the outcomes and business metrics, and automating the \r\nprocesses for more holistic metrics, and incrementally improving step by step. This practice \r\nmight be called ‚ÄúA/B experimentation‚Äù or ‚ÄúML Ops‚Äù or ‚ÄúMetrics Driven development\", but \r\nthey derive from the same general approach and we will rely on those principles for Agent \r\nOps as well.\r\nRemember that new practices don't replace the old. DevOps and MLOps best practices \r\nare still necessary for AgentOps, as they are dependencies. For example, Agent tool use, \r\nwhere APIs are invoked based on agent orchestration, often uses the same APIs you would \nAgents Companion\r\nFebruary 2025 10\r\ninvoke with non-agentic software. Authentication and secret management, security, privacy, \r\nexception handling, throttling, quotas, and scalability are still critical and require careful API \r\ndesign in addition to Agent design.\r\nLet‚Äôs go ahead and define these ‚Äúops‚Äù terms to help distinguish between them:\r\n‚Ä¢ Development and Operations (DevOps) is the practice of efficiently productionizing \r\ndeterministic software applications by integrating the elements of people, processes, and \r\ntechnology. DevOps serves as the foundation for all the following terms.\r\n‚Ä¢ Machine Learning Operations (MLOps) builds upon the capabilities of DevOps and \r\nconcentrates on the efficient productionization of ML models. The primary distinction is \r\nthat the output of an ML model is non-deterministic and relies on the input data (garbage \r\nin, garbage out).\r\n‚Ä¢ Foundation Model Operations (FMOps) expands upon the capabilities of MLOps \r\nand focuses on the efficient productionization of pre-trained (trained from scratch) or \r\ncustomized (fine-tuned) FMs.\r\n‚Ä¢ Prompt and Operations (PromptOps) is a subcategory of GenAIOps that focuses \r\non operationalizing prompts effectively. Its main additional capabilities include prompt \r\nstorage, lineage, metadata management (including evaluation scores), a centralized \r\nprompt template registry, and a prompt optimizer.\r\n‚Ä¢ RAG and Operations (RAGOps) is a subcategory of GenAIOps that centers on efficiently \r\noperationalizing RAG solutions. Its primary additional capabilities include the retrieval \r\nprocess through offline data preparation (encompassing cleaning, chunking, vectorization, \r\nsimilarity search, and re-ranking) and the generation process through prompt \r\naugmentation and grounding.\nAgents Companion\r\nFebruary 2025 11\r\n‚Ä¢ Agent and Operations (AgentOps) is a subcategory of GenAIOps that focuses on the \r\nefficient operationalization of Agents. Its main additional components include internal \r\nand external tool management, agent brain prompt (goal, profile, instructions) and \r\norchestration, memory, and task decomposition.\r\nFigure 2. Each of these ‚ÄúOps‚Äù are about technology, processes, and people14\r\nAll of these ‚ÄúOps‚Äù are, in essence, the harmonious blend of people, processes, and \r\ntechnologies working together to efficiently deploy machine learning solutions into a \r\nlive production environment. It‚Äôs crucial to recovgnize that Ops extends beyond mere \r\ntechnology; it‚Äôs not simply about constructing and delivering a ML pipeline. Successful Ops \r\nimplementations delve deeper, considering the customer‚Äôs operational model, their existing \r\nbusiness units, and their overall organizational structure. This holistic approach ensures that \r\nthe technology is tailored to their specific needs, seamlessly integrating into the business \r\nand maximizing value.\nAgents Companion\r\nFebruary 2025 12\r\nThe next section will cover Agent Evaluation in detail, which is a significant part of the story \r\nfor Agent Ops and automation to capture useful metrics. Before we go there, let‚Äôs start with a \r\nthought experiment; imagine setting up an A/B experiment in production for your new Agent. \r\nThe treatment arm gets your new agent and the control arm does not. In that scenario, what \r\nmetrics are you measuring to determine if the treatment arm is doing better? What metrics \r\nare you measuring to determine ROI for the project? Is it a goal being accomplished, or \r\nsales totals, or a set of critical steps in a user journey? Those metrics must be understood, \r\ninstrumented and easily analyzed in addition to more detailed Agent Evaluation metrics.\r\nAgent Success Metrics\r\nMetrics are critical to building, monitoring, and comparing revisions of Agents. Business \r\nmetrics, like revenue or user engagement, are probably outside of the scope of the agent \r\nitself but these should be the north star metric for your agents.\r\nMost Agents are designed around accomplishing goals, so goal completion rate is a key \r\nmetric to track. Similarly, a goal might be broken down into a few critical tasks or critical \r\nuser interactions. Each of these critical tasks and interactions should be independently \r\ninstrumented and measured.\r\nSo before we get into the details of the Agent itself, we already have several metrics \r\nidentified which you should be able to easily track on a dashboard. Each business metric, \r\ngoal, or critical interaction, will be aggregated in a familiar fashion: attempts, successes, \r\nrates, etc. Additionally, metrics you should be able to get from any application telemetry \r\nsystem are very important to track for agents as well, metrics like latency, errors, etc.\nAgents Companion\r\nFebruary 2025 13\r\nNone of these metrics are specific to Agents, you could track them for any software, but they \r\nare even more important for Agent builders. Deterministic code does only what you tell it to \r\ndo, whereas an agent can do a lot more, relying on LLMs which are trained on huge amounts \r\nof data. Instrumentation of these high level metrics is an important part of observability. \r\nYou can think of them as Key Performance Indicators (KPI) for the agent, and they allow for \r\nobservability in the aggregate, a higher level perspective of your agents.\r\nHuman feedback is one of the more critical metrics to track as well. A simple üëçüëé or user \r\nfeedback form, within the context of an agent or task can go a long way to understanding \r\nwhere your agent does well and where it needs improvement. This feedback can come from \r\nend users of a consumer system, but also employees, QA testers, and process or domain \r\nexperts reviewing the agent.\r\nMore detailed observability is also very important for agent building, being able to see and \r\nunderstand what the agent is doing and why it‚Äôs doing that. An agent can be instrumented \r\nwith ‚Äútrace‚Äù to log all of the inner workings of the agent, not only the critically important \r\ntasks and user interactions. You could conceptually measure every internal step as metrics, \r\nbut that is rarely done. Instead these detailed traces are used to debug an agent when \r\nmetrics or manual testing show a problem, you can dig into details and see what went wrong.\nAgents Companion\r\nFebruary 2025 14\r\nFigure 3: An example of Cloud Observability showing traces for an agent with tools and LLM \r\nOpenTelemetry spans.15\r\nSo far we‚Äôve been talking about business metrics, goals, tasks, human feedback, and traces \r\n‚Äì those are all ways of understanding the actions and impact of your agents, in production. \r\nWhile developing an agent, in addition to manual testing, automated testing will be much \r\nmore efficient in the long run and provide greater insights into the behavior of agents.\r\nAgent Evaluation\r\nTo bridge the gap between a proof-of-concept and a production-ready AI agent, a robust \r\nand automated evaluation framework is essential. Unlike evaluating generative models, where \r\nthe focus is primarily on the final output, agent evaluation requires a deeper understanding of \r\nthe decision-making process. Agent evaluation can be broken down into three components \r\nthat we discuss in this chapter:\r\n1. Assessing Agent Capabilities: Evaluating an agent's core abilities, such as its capacity to \r\nunderstand instructions and reason logically.\nAgents Companion\r\nFebruary 2025 15\r\n2. Evaluating Trajectory and Tool Use: Analyzing the steps an agent takes to reach a \r\nsolution, including its choice of tools, strategies, and the efficiency of its approach.\r\n3. Evaluating the Final Response: Assessing the quality, relevance, and correctness of the \r\nagent's final output.\r\nAssessing Agent Capabilities\r\nBefore evaluating your specific agentic use cases, publicly available benchmarks and \r\ntechnical reports can provide insight into core capabilities and limitations to consider when \r\nbuilding out your agentic use cases. Public benchmarks exist for most fundamental agentic \r\ncapabilities like model performance, hallucinations, tool calling and planning. For example, \r\ntool calling, the ability to select and use appropriate tools, is demonstrated by benchmarks \r\nlike the Berkeley Function-Calling Leaderboard (BFCL)16 and œÑ-bench17 that also outlines \r\ncommon mistakes. Another example, PlanBench18 aims to assess planning and reasoning, \r\nacross several domains and specific capabilities. \r\nBut tool calling and planning is not the only capability you should consider. Agents inherit \r\nbehaviors from their LLMs and each of their other components. Likewise, agent and user \r\ninteractions have a history in traditional conversational design systems and workflow \r\nsystems, and therefore can inherit the set of metrics and measurements that are used to \r\ndetermine the efficacy of these systems. \nAgents Companion\r\nFebruary 2025 16\r\nFigure 4: A high level diagram of AgentBench.19\r\nHolistic agent benchmarks like AgentBench19 try to capture end to end performance across \r\nseveral scenarios. This is more realistic, when the scenario reflects your agent use case, \r\nbut not if it‚Äôs testing capabilities your agent doesn‚Äôt implement. It is difficult to simulate \r\nthe environment, tools, instructions, and use case requirements in ways that are both \r\nspecific and general at the same time. Companies and organizations are setting up public \r\nbenchmarks for specialized use cases, like Adyen‚Äôs Data Analyst leaderboard DBAStep20\r\nwhich may give you a more targeted evaluation - if you understand both the evaluation \r\napproach and the agents who are on the leaderboard.\r\nPublic benchmarks are a valuable starting point, to get a feeling for what is possible and \r\nidentify pitfalls to look out for. Most benchmark assessments include discussions of common \r\nfailure modes that can guide you in setting up your own, use-case specific evaluation \r\nframework. \nAgents Companion\r\nFebruary 2025 17\r\nBeyond public evaluations, you will want to evaluate the behavior of your agent across a \r\nvariety of scenarios to ensure it does what you want it to do. You are simulating interactions \r\nwith your agent and evaluating how it responds. This includes the evaluating final response \r\nand also the set of steps it takes along the way (trajectory). Those are the 2 most common \r\nand practical approaches we recommend you start with. There are many other evaluation \r\ntechniques you can use beyond these, either for finer details on sub-components or \r\nbroader approaches.\r\nSoftware engineers will compare this to automated testing of code. Investing in automated \r\ntests saves you time and gives you confidence in the software you are building. With agents, \r\nthis automation pays off faster, in both time and confidence. Curating the evaluation data \r\nset will be extremely important for accurately representing the use case your agent will \r\nencounter, even more so than in software testing. \r\nEvaluating Trajectory and Tool Use\r\nAn agent usually does several actions before it responds back to the user. It might compare \r\nthe user input with session history to disambiguate a term, or lookup a policy document, \r\nsearch a knowledge base or invoke an API to save a ticket. Each of those actions is a step on \r\na path, also called a ‚Äútrajectory‚Äù of actions. Every time your agent does something, there‚Äôs a \r\ntrajectory of actions under the hood.\r\nComparing the trajectory that you expect the agent to take vs the trajectory that the agent \r\nactually took, is particularly useful for developers who want to debug their application, \r\nidentifying errors or inefficiencies, and ultimately improving performance. \nAgents Companion\r\nFebruary 2025 18\r\nFigure 5: LangSmith diagram of final evaluation and trajectory.21\r\nThe following six ground-truth-based automated trajectory evaluations provide different \r\nlenses to assess the performance of an agent:\r\n1. Exact match: Requires the AI agent to produce a sequence of actions (a \"trajectory\") that \r\nperfectly mirrors the ideal solution. This is the most rigid metric, allowing no deviation from \r\nthe expected path. \r\n2. In-order match: This metric assesses an agent's ability to complete the expected \r\ntrajectory, while accommodating extra, unpenalized actions. Success is defined by \r\ncompleting the core steps in order, with flexibility for additional actions.\r\n3. Any-order match: Compared to in-order match, this metric now disregards the order. It \r\nasks if the agent included all necessary actions, but does not look into the order of actions \r\ntaken and also allows for extra steps.\nAgents Companion\r\nFebruary 2025 19\r\n4. Precision: How many of the tool calls in the predicted trajectory are actually relevant or \r\ncorrect according to the reference trajectory?\r\n5. Recall: How many of the essential tool calls from the reference trajectory are actually \r\ncaptured in the predicted trajectory?\r\n6. Single-tool use: Understand if a specific action is within the agent's trajectory. This \r\nmetric is useful to understand if the agent has learned to utilize a particular tool yet.\r\nFigure 6: A radar chart plotting a single trajectory evaluation with a few metrics.24\nAgents Companion\r\nFebruary 2025 20\r\nConsider these metrics as different lenses for analyzing and debugging your agent's \r\ntrajectory. Each metric offers a unique perspective, but not all will be relevant to every \r\nsituation. For instance, some use cases demand strict adherence to the ideal trajectory, while \r\nothers allow for more creative deviations. A clear limitation of this evaluation approach is that \r\nyou need to have a reference trajectory in place for this to work. While ground-truth-based \r\nautomated trajectory evaluations that are discussed here are prevalent in popular libraries. \r\nResearch is advancing the use of agent autoraters for more efficient evaluation, for example \r\nAgent as a Judge, 202422.\r\nEvaluating the Final Response\r\nThe final response evaluation boils down to a simple question: Does your agent achieve its \r\ngoals? You can define custom success criteria, tailored to your specific needs, to measure \r\nthis. For example, you could assess whether a retail chatbot accurately answers product \r\nquestions, or whether a research agent effectively summarizes findings with the appropriate \r\ntone and style. To automate this process, you can use autorater. An autorater is an LLM \r\nthat acts as a judge. Given the input prompts and the generated response, it mirrors \r\nhuman evaluation by assessing the response against a set of user-provided criteria. For \r\nthis evaluation to work, it is crucial to consider that given the absence of ground-truth, you \r\nneed to be very precise in defining your evaluation criteria, as this is the core of what your \r\nevaluation is looking at. You find a number of predefined criteria in various libraries, treat \r\nthem as a starting point and tweak them to provide your definition of good. \nAgents Companion\r\nFebruary 2025 21\r\nHuman-in-the-Loop Evaluation\r\nThe fields of agent development and agent evaluation are rapidly evolving. Evaluating \r\nAI agents presents significant challenges, including defining clear objectives, designing \r\nrealistic environments, managing stochastic behavior, and ensuring fairness and bias \r\nmitigation, particularly in socially impactful applications. Therefore, it's crucial to incorporate \r\na human-in-the-loop approach alongside the automated evaluations discussed previously \r\n(which involve predefined metrics and autoraters). Human-in-the-loop is valuable for tasks \r\nrequiring subjective judgment or creative problem-solving, it can also serve to calibrate and \r\ndouble-check if your automated evaluation approaches actually work and align with your \r\npreferences. Key benefits include:\r\n‚Ä¢ Subjectivity: Humans can evaluate qualities that are difficult to quantify, such as \r\ncreativity, common sense, and nuance.\r\n‚Ä¢ Contextual Understanding: Human evaluators can consider the broader context of the \r\nagent's actions and their implications.\r\n‚Ä¢ Iterative Improvement: Human feedback provides valuable insights for refining the \r\nagent's behavior and learning process.\r\n‚Ä¢ Evaluating the evaluator: Human feedback can provide a signal to calibrate and refine \r\nyour autoraters. \r\nTo implement human-in-the-loop evaluation, consider these methods:\r\n‚Ä¢ Direct Assessment: Human experts directly rate or score the agent's performance on \r\nspecific tasks.\r\n‚Ä¢ Comparative Evaluation: Experts compare the agent's performance to that of other \r\nagents or your previous iterations. \nAgents Companion\r\nFebruary 2025 22\r\n‚Ä¢ User Studies: Participants interact with the agent and provide feedback on its behavior, \r\nusability, and overall effectiveness.\r\nMore about Agent Evaluation\r\nIn this section we cover agent evaluation from the practical perspective. But this is just the tip \r\nof the iceberg. Agent evaluation presents many challenges. Evaluation data for your agents \r\nmay be difficult to find. While synthetic data or LLMs as judges can be used, evaluations \r\nmay still be incomplete. Also, LLM-as-a-Judge metrics, for example, may prioritize final \r\noutcomes over the agent's reasoning and intermediate actions, potentially missing key \r\ninsights. Additionally, as evaluations for agent systems have a history in conversational and \r\nworkflow systems, there is so much to explore on how to inherit methods and metrics to \r\nevaluate agent's capabilities, such as the ability to improve task performance over multiple \r\ninteractions. Evaluations for multi-modal generations pose additional complexities; images, \r\naudio, and video evaluations require their own evaluation methods and metrics. Finally, real\u0002world environments pose further challenges, as they are dynamic and unpredictable, making \r\nit difficult to evaluate agents in controlled settings.\r\nLooking ahead, to solve these open challenges, the field of agent evaluation is evolving \r\nrapidly. Key trends include a shift towards process-based evaluation, prioritizing the \r\nunderstanding of agent reasoning; an increase in AI-assisted evaluation methods for \r\nimproved scalability; and a stronger focus on real-world application contexts. The \r\ndevelopment of new standardized benchmarks is also gaining traction, facilitating objective \r\ncomparisons between agents, while increased emphasis on explainability and interpretability \r\naims to provide deeper insights into agent behavior.\nAgents Companion\r\nFebruary 2025 23\r\nTable 1: A table comparing strengths and weaknesses of automated evaluations for Agents.\r\nAt this point it should be clear that only by continually refining evaluation methods, we will \r\nensure that AI agents are developed and deployed responsibly, effectively, and ethically in \r\nthe coming future. \r\nMultiple Agents & Their Evaluation\r\nAgent evaluation, which assesses the effectiveness, reliability, and adaptability of \r\nautonomous AI agents, as seen in the previous section, has emerged as a key focus area. \r\nWe have seen a significant evolution in AI systems, transitioning towards multi-agent \r\narchitectures‚Äîwhere multiple specialized agents collaborate to achieve complex objectives. \r\nA multi-agent system is like a team of experts, each specializing in a particular area, working \r\ntogether to solve a complex problem. Each agent is an independent entity, potentially using a \r\ndifferent LLM, and with its own unique role and context. Agents communicate and collaborate \r\nto achieve a common goal. This approach differs from traditional single-agent systems, \r\nwhere one LLM handles all aspects of a task.\r\nEvaluation Method Strengths Weaknesses\r\nHuman Evaluation Captures nuanced behavior, \r\nconsiders human factors\r\nSubjective, time-consuming, \r\nexpensive, difficult to scale\r\nLLM-as-a-Judge Scalable, efficient, consistent May overlook intermediate steps, \r\nlimited by LLM capabilities\r\nAutomated Metrics Objective, scalable, efficient May not capture full capabilities, \r\nsusceptible to gaming\nAgents Companion\r\nFebruary 2025 24\r\nMulti-agent systems offer several advantages over single-agent systems:\r\n‚Ä¢ Enhanced Accuracy: Agents can cross-check each other's work, leading to more \r\naccurate results.\r\n‚Ä¢ Improved Efficiency: Agents can work in parallel, speeding up task completion.\r\n‚Ä¢ Better Handling of Complex Tasks: Large tasks can be broken down into smaller, more \r\nmanageable subtasks, with each agent focusing on a specific aspect.\r\n‚Ä¢ Increased Scalability: The system can be easily scaled by adding more agents with \r\nspecialized capabilities.\r\n‚Ä¢ Improved Fault Tolerance: If one agent fails, others can take over its responsibilities.\r\n‚Ä¢ Reduced Hallucinations and Bias: By combining the perspectives of multiple agents, \r\nthe system can reduce the effects of hallucinations and bias, leading to more reliable and \r\ntrustworthy outputs.\r\nUnderstanding Multi-Agent Architectures\r\nUnlike traditional monolithic AI systems, multi-agent architectures break down a problem \r\ninto distinct tasks handled by specialized agents. Each agent operates with defined roles, \r\ninteracting dynamically with others to optimize decision-making, knowledge retrieval, and \r\nexecution. These architectures enable more structured reasoning, decentralized problem\u0002solving, and scalable task automation, offering a paradigm shift from single-agent workflows.\r\nAt their core, multi-agent systems leverage principles of modularity, collaboration, and \r\nhierarchy to create a robust AI ecosystem. Agents within these systems can be categorized \r\nbased on their function for example:\nAgents Companion\r\nFebruary 2025 25\r\n‚Ä¢ Planner Agents: Responsible for breaking down high-level objectives into \r\nstructured sub-tasks.\r\n‚Ä¢ Retriever Agents: Optimize knowledge acquisition by dynamically fetching relevant data \r\nfrom external sources.\r\n‚Ä¢ Execution Agents: Perform computations, generate responses, or interact with APIs.\r\n‚Ä¢ Evaluator Agents: Monitor and validate responses, ensuring coherence and alignment \r\nwith objectives.\r\nThrough these components, multi-agent architectures extend beyond simple prompt-based \r\ninteractions, enabling AI-driven workflows that are adaptive, explainable, and efficient.\r\nMulti-Agent Design Patterns and Their Business Impact\r\nTo design effective multi-agent architectures, specific design patterns have emerged. These \r\npatterns define interaction protocols, delegation mechanisms, and role distributions, allowing \r\nbusinesses to implement AI-driven automation in structured ways. Some common design \r\npatterns include:\nAgents Companion\r\nFebruary 2025 26\r\nTable 2: A table comparing types of multi-agent systems.\r\nType of Multi-Agent System Description Example\r\nSequential\r\nAgents work in a sequential \r\nmanner, with each agent \r\ncompleting its task before \r\npassing the output to the \r\nnext agent.\r\nAn assembly line, where each \r\nworker performs a specific \r\noperation before passing the \r\nproduct to the next worker.\r\nHierarchical\r\nAgents are organized in a \r\nhierarchical structure, with a \r\n\"manager\" agent coordinating the \r\nworkflow and delegating tasks to \r\n\"worker\" agents.\r\nA system with a leader agent \r\nresponsible for making strategic \r\ndecisions and follower agents \r\nexecuting tasks based on the \r\nleader's instructions.\r\nCollaborative\r\nAgents work together \r\ncollaboratively, sharing \r\ninformation and resources to \r\nachieve a common goal.\r\nA team of researchers working \r\non a project, where each member \r\ncontributes their expertise \r\nand insights.\r\nCompetitive\r\nAgents may compete with \r\neach other to achieve the \r\nbest outcome.\r\nLLMs act as individual players in a \r\ngame like Overcooked-AI, where \r\nthey must coordinate their actions \r\nto achieve a shared goal while \r\ncompeting for resources and \r\noptimizing individual performance.\nAgents Companion\r\nFebruary 2025 27\r\nFigure 7: An image depicting different multi-agent topologies, from LangGraph documentation.23\r\nThe choice of design pattern depends on the specific application and the desired level of \r\ninteraction between agents.\r\nBusinesses benefit from these patterns by reducing operational bottlenecks, improving \r\nknowledge retrieval, and enhancing automation reliability. Multi-agent systems enable \r\ncompanies to scale AI deployments while ensuring agility in decision-making and \r\nworkflow execution.\nAgents Companion\r\nFebruary 2025 28\r\nImportant components of Agents\r\nThe architecture of LLM-based AI agents consists of several interrelated components \r\nessential for autonomous operation and intelligent interaction:\r\n‚Ä¢ Interaction Wrapper: This component serves as the interface between the agent \r\nand its environment, managing communication and adapting to various input and \r\noutput modalities.\r\n‚Ä¢ Memory Management: This includes short-term working memory for immediate context, \r\ncache, and sessions . It also can include long-term storage for learned patterns and \r\nexperiences, as episodes, examples, skills or reference data. It also includes ‚Äúreflection‚Äù \r\nto decide which short term items (eg: user preference) should be copied into long term \r\nmemory (eg: user profile), and if that can be shared across agents, tasks, or sessions.\r\n‚Ä¢ Cognitive Functionality: This is often underpinned by Chain-of-Thought (CoT), ReACT, \r\nreasoning, thinking, or a planner subsystem - it allows agents to decompose complex \r\ntasks into logical steps and engage in self-correction. In some cases this also includes \r\nuser intent refinement, to ask a clarifying question if uncertain.\r\n‚Ä¢ Tool Integration: This subsystem enables agents to utilize external tools, expanding \r\ntheir capabilities beyond natural language processing. Dynamic tool registries allowing \r\ndiscovery, registration, and ‚ÄúTool RAG‚Äù.\r\n‚Ä¢ Flow / Routing: This governs connections with other agents, facilitating dynamic neighbor \r\ndiscovery and efficient communication within the multi-agent system. This might be \r\nimplemented as a delegation of a task to a background agent, or handoff of the user \r\ninteraction to an agent, or the use of an agent as a tool.\nAgents Companion\r\nFebruary 2025 29\r\n‚Ä¢ Feedback Loops / Reinforcement Learning: These enable continuous learning and \r\nadaptation by processing interaction outcomes and refining decision-making strategies. \r\nFor gen AI agents this rarely takes the form of traditional RL training, but the performance \r\nmetrics of the past can be incorporated into future decision making.\r\n‚Ä¢ Agent Communication: Effective communication between agents is crucial for the \r\nsuccess of multi-agent systems. The Agent to Agent communication protocol facilitates \r\nstructured and efficient communication among agents, enabling them to achieve \r\nconsensus and address complex problems collaboratively\r\n‚Ä¢ Remote Agent Communication: Agent to Agent communication within an organization \r\nis critical to allows agents to share messages, tasks, and knowledge. Once your multi\u0002agent system includes a remote agent, the communication protocol becomes even more \r\nimportant. Asynchronous tasks and sessions need to be durable, and updated with \r\nnotifications while end users are not in session. Negotiations between Agents must allow \r\nfor bringing a user into session and for supported UX capabilities. \r\n‚Ä¢ Agent & Tool Registry (mesh): As you go beyond a handful of tools or a handful of \r\nagents, you need a robust system to discover, register, administer, select and utilize from \r\na ‚Äúmesh‚Äù of tools or agents. Critically important is the ontology and description of the \r\ntools and agents, their capabilities and requirements, and their performance metrics. Your \r\nagents will make a plan and choose which tool or which agent to use from such a system, \r\nand those choices are informed by the data in the system\nAgents Companion\r\nFebruary 2025 30\r\nFigure 8: An image demonstrating the process of a user interacting with multiple, self-coordinating agents.24\r\nThese architectural elements provide a robust foundation for the autonomous operation and \r\ncollaborative capabilities of LLM agents within multi-agent systems.\nAgents Companion\r\nFebruary 2025 31\r\nChallenges in Multi-Agent systems \r\nWhile multi-agent systems offer numerous advantages, they also face several challenges:\r\n‚Ä¢ Task Communication: Today most agent frameworks communicate in messages, not \r\nstructured async tasks.\r\n‚Ä¢ Task Allocation: Efficiently dividing complex tasks among different agents can be \r\nchallenging, and feedback loops are often left up to the developer to implement.\r\n‚Ä¢ Coordinating Reasoning: Getting agents to debate and reason together effectively \r\nrequires sophisticated coordination mechanisms.\r\n‚Ä¢ Managing Context: Keeping track of all the information, tasks, and conversations \r\nbetween agents can be overwhelming.\r\n‚Ä¢ Time and Cost: Multi-agent interactions can be computationally expensive and time\u0002consuming. This results in higher runtime prices and more user latency.\r\n‚Ä¢ Complexity: In the same way that microservice architecture allows each microservice \r\nmore flexibility and simplicity, the system as a whole usually becomes more complex. \r\nAddressing these challenges is crucial for developing robust and efficient \r\nmulti-agent systems.\nAgents Companion\r\nFebruary 2025 32\r\nMulti-Agent Evaluation\r\nLuckily, the evaluation of multi-agent systems is a clear progression of evaluating single \r\nagent systems. Agent Success Metrics are unchanged, business metrics as your north star, \r\ngoals and critical task success metrics, application telemetry metrics like latency and errors. \r\nInstrumenting the multi-agent system with trace will help debug and understand what is \r\nhappening during complex interactions.\r\nIn the Agent Evaluation section we discussed Evaluating Trajectories and Evaluating the Final \r\nResponse as the 2 best approaches to automated evaluation of an agent, and this remains \r\nthe case for multi-agent systems. For a multi-agent system, a trajectory of actions might \r\ninclude several or even all of your agents. Even though several agents may collaborate on a \r\ntask, a single final answer is returned to the user at the end and can be evaluated in isolation.\r\nBecause a multi-agent system probably has more steps, you can drill down and evaluate at \r\nevery step. You can evaluate each of your agents in isolation and the system as a whole. \r\nTrajectory evaluations are a scalable approach to do exactly this.\r\nThere are some questions you need to ask, which are unique to multi-agent \r\nsystems, including:\r\n‚Ä¢ Cooperation and Coordination: How well do agents work together and coordinate their \r\nactions to achieve common goals?\r\n‚Ä¢ Planning and Task Assignment: Did we come up with the right plan, and did we stick to \r\nit? Did child agents deviate from the main plan or get lost in a cul-de-sac?\r\n‚Ä¢ Agent Utilization: How effectively do agents select the right agent and choose to use the \r\nagent as a tool, delegate a background task, or transfer the user?\nAgents Companion\r\nFebruary 2025 33\r\n‚Ä¢ Scalability: Does the system's quality improve as more agents are added? Does the \r\nlatency go down? Are we being more efficient or less?\r\nThese types of questions can guide developers to identify areas for improvement in the \r\nmulti-agent system. You will answer these questions using the same tools you use for single \r\nagent systems, but the complexity of the analysis goes up.\r\nAgentic RAG: A Critical Evolution in \r\nRetrieval-Augmented Generation\r\nA significant advancement in multi-agent architectures is Agentic Retrieval-Augmented \r\nGeneration (Agentic RAG). Traditional RAG pipelines rely on a static approach‚Äîretrieving \r\nknowledge from vector databases and feeding it into an LLM for synthesis. However, this \r\napproach often fails when dealing with ambiguous, multi-step, or multi-perspective queries.\r\nAgentic RAG introduces autonomous retrieval agents that actively refine their search \r\nbased on iterative reasoning. These agents enhance retrieval in the following ways:\r\n‚Ä¢ Context-Aware Query Expansion: Instead of relying on a single search pass, agents \r\ngenerate multiple query refinements to retrieve more relevant and comprehensive results.\r\n‚Ä¢ Multi-Step Reasoning: Agents decompose complex queries into smaller logical steps, \r\nretrieving information sequentially to build structured responses.\r\n‚Ä¢ Adaptive Source Selection: Instead of fetching data from a single vector database, \r\nretrieval agents dynamically select the best knowledge sources based on context.\r\n‚Ä¢ Validation and Correction: Evaluator agents cross-check retrieved knowledge for \r\nhallucinations and contradictions before integrating it into the final response.\nAgents Companion\r\nFebruary 2025 34\r\nThis approach significantly improves response accuracy, explainability, and adaptability, \r\nmaking it a crucial innovation for enterprises dealing with complex knowledge retrieval tasks \r\nin areas like legal research, scientific discovery, and business intelligence.\r\nAgentic RAG and its Importance\r\nAgentic RAG (Retrieval-Augmented Generation) is an advanced approach that combines the \r\nstrengths of RAG with the autonomy of AI agents. Traditional RAG systems retrieve relevant \r\ninformation from external knowledge sources to enhance LLM responses. Agentic RAG \r\ntakes this a step further by employing intelligent agents to orchestrate the retrieval process, \r\nevaluate the retrieved information, and make decisions about how to best utilize it.\r\nAgentic RAG offers several advantages over traditional RAG:\r\n‚Ä¢ Improved Accuracy: Agents can evaluate the quality of retrieved information and make \r\ndecisions about which sources to trust, leading to more accurate and reliable responses.\r\n‚Ä¢ Enhanced Contextual Understanding: Agents can consider the context of the user's \r\nquery and the retrieved information to generate more relevant and meaningful responses.\r\n‚Ä¢ Increased Adaptability: Agents can adapt to changing information needs and \r\ndynamically adjust their retrieval strategies to provide the most up-to-date and relevant \r\ninformation. This adaptability is crucial in complex domains where information is constantly \r\nevolving, such as healthcare, finance, and legal research.\nAgents Companion\r\nFebruary 2025 35\r\nFigure 9: A diagram of Agentic RAG from Vectorize.io.25\r\nAgentic RAG is particularly valuable in complex domains where information is constantly \r\nevolving, such as healthcare, finance, and legal research. For example, in healthcare, agentic \r\nRAG can help navigate complicated medical databases, research papers, and patient \r\nrecords, providing doctors with comprehensive and accurate information.\nAgents Companion\r\nFebruary 2025 36\r\nBetter Search, Better RAG\r\nAlmost all RAG approaches require a search engine to index and retrieve relevant data. The \r\nintroduction of agents allows for refinement of query, filtering, ranking, and the final answer. \r\nAgentic RAG agents are executing several searches to retrieve information.\r\nFor developers who are trying to optimize existing RAG implementations, it is usually most \r\nvaluable to improve search results (measured in recall) prior to introducing agents. Some of \r\nthe main techniques to improve search performance are:\r\n‚Ä¢ Parse source documents and chunk them: Vertex AI Layout Parser can handle complex \r\ndocument layouts, embedded tables, and embedded images like charts, and uses a \r\nsemantic chunker to keep chunks on topic with a hierarchy of headings.\r\n‚Ä¢ Add metadata to your chunks: synonyms, keywords, authors, dates, tags and categories \r\nallow your searches to boost, bury, and filter; these allow your users or your agents more \r\ncontrol over search results.\r\n‚Ä¢ Fine tune the embedding model or add a search adaptor which changes embedding \r\nspace: these allow the searchable index of vectors to represent your domain better than a \r\ngeneral purpose embedding model.\r\n‚Ä¢ A faster vector database can improve search quality: to search embeddings, you must \r\nmake a tradeoff between speed and accuracy, upgrading to an ultra-fast Vertex AI \r\nVector Search can improve both latency and quality\r\n‚Ä¢ Use a ranker: vector searches are fast but approximate, they should return dozens or \r\nhundreds of results which need to be re-ranked by a more sophisticated system to ensure \r\nthe top few results are the most relevant or best answer.\r\n‚Ä¢ Implement check grounding: as a safeguard on grounded generation, you can ensure \r\neach phrase is actually citable by retrieved chunks.\nAgents Companion\r\nFebruary 2025 37\r\nFigure 10: A diagram of common RAG and search components, showing Vertex AI Search26, search builder \r\nAPIs27, and RAG Engine.28\r\nVertex AI Search26 is a powerful search engine providing Google quality search for your \r\ndata and can be used with any RAG or Agentic RAG implementation. Each of the above \r\ncomponents is automatically available within Vertex AI Search, without any development \r\ntime at all. For developers who want to build their own search engine, each of the above \r\ncomponents is exposed as a stand alone API27, and RAG Engine28 can orchestrate the whole \r\npipeline easily, with a LlamaIndex like python based interface.\nAgents Companion\r\nFebruary 2025 38\r\nAgents in the enterprise\r\nManager of agents\r\n2025 is the year of the agents, and this will particularly be true in the context of enterprises \r\nthat will develop and use agents that will assist employees to perform specific tasks \r\nor autonomously run in the background performing automation. Business analysts can \r\neffortlessly uncover industry trends and create compelling, data-driven presentations \r\nfueled by AI-generated insights. HR teams can revolutionize the employee experience with \r\nstreamlined onboarding, even for complex tasks like 401k selection. Software engineers \r\ncan proactively identify and resolve bugs, enabling them to build and iterate with greater \r\nefficiency, and accelerate deployment cycles. Marketers can unlock deeper performance \r\nanalysis, optimize content recommendations, and fine-tune campaigns effortlessly to achieve \r\nbetter results. \r\nWe see two types of agents emerging:\r\n1. ‚ÄúAssistants‚Äù: Agents that interact with the user, take a task, execute it, and come back \r\nto the user. Conversational agents popularized by frameworks like Gems or GPTs usually \r\nbelong to this category. Assistants can be general - able to help on a variety of tasks - or \r\nspecialized to a particular domain, or tasks. Examples include agents that help schedule \r\nmeetings, analyze data, write code, write marketing press releases, help sellers with \r\nsales opportunities, or even agents that perform deep research on a particular topic \r\nas requested by the user. These agents can be synchronous and return the requested \r\ninformation or perform the requested task fast, or they run for a longer period of time \r\nbefore returning (like the deep research agents). \nAgents Companion\r\nFebruary 2025 39\r\n2. \"Automation agents‚Äù: Agents that run in the background, listen to events, monitor \r\nchanges in systems or data, and then make smart decisions and act. Action might include \r\nacting on backend systems, performing some tests to validate the observation, fixing \r\nproblems, notifying the right employees, etc. This can really be seen as the backbone of \r\nthe automation of the future. While in the past we had to write special code to specify \r\nthe logic of automations, now we can start relying on smart and general decision making \r\nabilities of AI agents.\r\nRather than simply invoking agents to perform a task and wait for the output, knowledge \r\nworkers will increasingly become managers of agents. They will be assigning tasks to multiple \r\nagents and manage them, check if any of agents need help or require approval to proceed, \r\nuse the output of specific agents to start new tasks, monitor execution of long running tasks \r\nto review and steer them in the right direction. Novel user interfaces to allow this type of \r\nvirtual team management will emerge to allow orchestration, monitoring and managing a \r\nmulti-agent system with agents performing tasks, calling (or even creating) other agents.\r\nGoogle Agentspace aims at providing this type of experience and allow to:\r\n‚Ä¢ Create new agents by using a no/low code interface or a full code framework to \r\nimplement both specialized assistants and automation agents\r\n‚Ä¢ Configure and manage the agents access for company administrators\r\n‚Ä¢ Invoke the right agents when appropriate\r\n‚Ä¢ Monitor, manage, and orchestrate multiple agents in a UI suited for team management\nAgents Companion\r\nFebruary 2025 40\r\nGoogle Agentspace\r\nGoogle Agentspace29 offers a suite of AI-driven tools designed to elevate enterprise \r\nproductivity by facilitating access to pertinent information and automating intricate, \r\nagentic workflows. It harnesses the advanced reasoning capabilities of Gemini, the power \r\nof Google's search infrastructure, and secure access to enterprise data, irrespective of its \r\nphysical location.\r\nAgentspace directly addresses the limitations inherent in traditional knowledge management \r\nsystems, which frequently fall short in areas such as personalization, automated answer \r\ngeneration, contextual comprehension, and comprehensive information retrieval. It \r\nempowers employees with efficient information access by consolidating disparate content \r\nsources, generating grounded and personalized responses, and streamlining operational \r\nworkflows. Key functionalities include the capacity to ingest a wide variety of data formats, \r\nsynchronize data from Software-as-a-Service (SaaS) platforms, deliver access-controlled \r\nsearch results and AI-generated answers, and integrate AI assistance and intelligent agents \r\ninto cohesive workflows.\r\nThe architecture of Agentspace Enterprise is founded upon several core principles. \r\nParamount among these is built-in trust, which prioritizes security, explainability, and \r\ngovernance through features such as single sign-on (SSO) authentication, an integrated \r\npermissions model, and user-level access controls. Google's advanced intelligence is \r\nleveraged to discern user behavior and content patterns through machine learning, resulting \r\nin the delivery of highly relevant results via semantic understanding, knowledge graphs, \r\nand LLMs. Universal connectivity is achieved by connecting to a diverse array of enterprise \r\nsystems with on-demand and automated data refreshes, thereby eliminating information \r\nsilos. Enterprise-level customization and user-level personalization are facilitated through \r\ngranular controls for search functionality, recommendations, LLMs, and knowledge graphs, \r\nproviding tailored experiences based on individual user roles, permissions, and search \nAgents Companion\r\nFebruary 2025 41\r\nhistory. Real-time feedback and adaptation mechanisms enable the continuous refinement \r\nof results through machine learning and user input. Blended Retrieval Augmented Generation \r\n(RAG) allows for customizable data blending, powering generative AI applications grounded \r\nin enterprise data. Finally, scalability is a critical design consideration, with the system \r\nengineered to accommodate growth across geographical regions, languages, and peak \r\nusage demands.\r\nSecurity is always top of mind. Google Agentspace is built on the Google Cloud secure-by\u0002design infrastructure, giving you the peace of mind to confidently deploy AI agents across \r\nyour organization. It provides granular IT controls, including role-based access control \r\n(RBAC), VPC Service Controls, and IAM integration, ensuring your data remains protected \r\nand compliant at all times.Security is a foundational principle of Agentspace. Built upon the \r\nsecure infrastructure of Google Cloud, it provides a robust environment for the deployment \r\nof AI agents. Granular IT controls, encompassing role-based access control (RBAC), \r\nVirtual Private Cloud (VPC) Service Controls, and Identity and Access Management (IAM) \r\nintegration, guarantee data protection and regulatory compliance. These security measures \r\nare essential for the safeguarding of sensitive information and give users the peace of mind \r\nto confidently deploy AI agents across their organization.\r\nNotebookLM Enterprise\r\nNotebookLM30 is a research and learning tool designed to streamline the process of \r\nunderstanding and synthesizing complex information. It empowers users to upload various \r\nsource materials, including documents, notes, and other relevant files, and leverages the \r\npower of artificial intelligence to facilitate deeper comprehension. Imagine researching a \r\nmultifaceted topic; NotebookLM allows you to consolidate all your scattered resources into \nAgents Companion\r\nFebruary 2025 42\r\na single, organized workspace. In essence, NotebookLM functions as a dedicated research \r\nassistant, accelerating the research process and enabling users to move beyond mere \r\ninformation collection to genuine understanding.\r\nFigure 11: NotebookLM Enterprise30 configured with a few mock earning reports.\r\nNotebookLM Plus builds upon this foundation, offering a premium tier with enhanced \r\nfeatures and capabilities. While the core functionality of uploading sources, asking questions, \r\nand generating summaries remains, NotebookLM Plus typically adds features like increased \r\nstorage for source materials, enabling work with larger and more complex projects. It \nAgents Companion\r\nFebruary 2025 43\r\nmay also include more sophisticated AI-powered analysis tools, such as more nuanced \r\nsummarization options, enhanced question-answering capabilities, or the ability to identify \r\nconnections and relationships between different sources more effectively.\r\nBuilding upon the foundation of NotebookLM Plus, NotebookLM Enterprise30 brings these \r\npowerful capabilities to the enterprise environment, streamlining how employees interact \r\nwith and derive insights from their data. This enterprise-grade version enables users to not \r\nonly upload and synthesize information, but also to uncover hidden patterns and engage with \r\ndata in innovative ways. A prime example is the AI-generated audio summary feature, which \r\nenhances comprehension and facilitates efficient knowledge absorption by allowing users to \r\n\"listen\" to their research. \r\nTechnically, NotebookLM, both in its consumer and enterprise forms, employs LLMs to \r\nprocess uploaded documents, extract key concepts, and generate summaries. The audio \r\nsummary feature uses text-to-speech (TTS) technology incorporating advanced prosody \r\ncontrol to ensure clarity and naturalness. Critically, NotebookLM Enterprise incorporates \r\nenterprise-grade security and privacy features, ensuring that sensitive company data is \r\nhandled with the utmost care and protected in accordance with organizational policies.`\r\nGoogle AgentSpace Enterprise\r\nGoogle Agentspace furnishes employees with a unified, company-branded, multimodal \r\nsearch agent that serves as the definitive source of enterprise information. Drawing upon \r\nGoogle's extensive search capabilities, Agentspace offers unparalleled conversational \r\nassistance. Employees get answers to complex queries, proactive recommendations, \r\nand unified access to information from any source. This functionality extends to both \r\nunstructured data, such as documents and emails, and structured data, like tables. \r\nIntegrated translation capabilities ensure comprehensive understanding, regardless of \nAgents Companion\r\nFebruary 2025 44\r\nthe original language of the information. Pre-built connectors for widely used third-party \r\napplications, including Confluence, Google Drive, Jira, Microsoft SharePoint, ServiceNow, \r\nand others, empower employees to seamlessly access and query relevant data sources, \r\nfacilitating more informed decision-making.\r\nFigure 12: Agentspace29 customized for Cymbal bank, connected to several data stores.\r\nMuch more than just information retrieval, agents can take actions in the real world, manage \r\nasync tasks and workflows, and help employees get work done. A gallery of agents can be \r\nconfigured based on an organization's unique needs and will help with deep research, idea \r\ngeneration and merit based refinement, creative asset generation, data analytics and more.\nAgents Companion\r\nFebruary 2025 45\r\nAgentspace Enterprise Plus facilitates the creation of custom AI agents tailored to specific \r\nbusiness functions. This platform enables the development and deployment of contextually \r\naware generative AI agents, empowering employees across departments‚Äîmarketing, \r\nfinance, legal, engineering, and more‚Äîto conduct more effective research, rapidly generate \r\ncontent, and automate repetitive tasks, including multi-step workflows. A centralized \r\ninterface streamlines the discovery and access of these specialized agents, promoting \r\nscalable AI adoption. Custom agents will connect with internal and external systems and \r\ndata, be tailored to company domain and policies, and potentially even utilize machine \r\nlearning models trained on proprietary business data. The platform provides builders tools \r\nfor agent development, deployment, and lifecycle managemen\nAgents Companion\r\nFebruary 2025 46\r\nFrom agents to contractors\r\nThe common interface to define AI agents across various tools and platforms today is very \r\nsimple, and usually includes specifying the goal, some textual instructions, the tools that the \r\nagent can use, and a set of examples. While this might be sufficient to prototype demos, it \r\nleads to potentially underspecified definitions, and might be one of the leading reasons that \r\nAI agents can struggle to get from prototype-to-production. \r\nWe propose to evolve the Agent interface to evolve them into ‚ÄùContract adhering agents‚Äù \r\nwhich are aimed at solving complex tasks using AI Agents, more specifically in contexts \r\nwhere stakes are high. \r\nContracts\r\nThe key idea of contractors is to specify and the standard the contracts between the \r\nrequester and the agents, making it possible to: \r\n1. Define the outcomes as precisely as possible, similarly to what we would do in a \r\nreal world scenario when agreeing on a service with a company we are contracting to \r\ndo something for us. This allows the agent (contractor) to validate against the desired \r\noutcomes and iterate until the desired objective is achieved. \r\n2. Make it possible to negotiate the task as well as clarifying and refining it, in order \r\nto avoid any ambiguity in the definition, and fill any gap in common understanding of \r\nthe goals.\r\n3. Define the rules for the contractors to generate new subcontracts needed to solve the \r\nbigger one in a standard fashion (cf. section below on subcontracts).\nAgents Companion\r\nFebruary 2025 47\r\n4.\r\nTable 3: An example data model for the contracts.\r\nContract, initial definition\r\nFields Description Required\r\nTask/Project\r\ndescription\r\nProvide a detailed description of what we expect the\r\ncontractor to achieve. It should be as specific and as non\u0002ambiguous as possible.Yes\r\nDeliverables &\r\nSpecifications\r\nDescribe precisely the expected outcomes and\r\ndeliverables from the contractor&#39;s task, including a list of\r\nspecifications clarifying what makes the deliverable\r\nacceptable as outcome and details on how to verify that\r\nthe deliverable is fulfilling the expectation.\r\nYes\r\nScope\r\nClarify the scope of the tasks that the contractor is\r\nresponsible for completing, going into separate detail\r\nabout every aspect of the task. Also used to clarify what is out \r\nof scope.\r\nNo \r\nExpected Cost\r\nGives expectation in terms of cost for the task completion.\r\nThis is usually a function of the complexity of the task\r\ncombined with what tools will be used.\r\nYes\r\nExpected Duration Gives expectation in terms of duration for the task completion. Yes\r\nInput Sources Specify what input sources can be used and considered to be \r\nuseful to complete the task. No\r\nReporting and\r\nFeedback\r\nSpecifies how the feedback loop should look like: how often we \r\nexpect updates on the progress, and what mechanism/surface \r\nis used to provide feedback (emails, APIs, etc.).\r\nYes\nAgents Companion\r\nFebruary 2025 48\r\nTable 4: An example data model for the iteration of messaging between contractors.\r\nContract Iteration: Feedback & Negotiation\r\nFields Description Required\r\nUnderspecification Highlight aspects that are underspecified or\r\nneed clarification from the task initiator. No\r\nCost negotiation Cost considered too high to complete the task. No\r\nRisk Highlights potential risks in fulfilling the contract. No \r\nAdditional input \r\nneeded\r\nExpress the kinds of additional data or information that would \r\nbe useful to fulfill the contract. No\nAgents Companion\r\nFebruary 2025 49\r\nContract Lifecycle\r\nThe following illustration shows the lifecycle of defining, negotiating and executing the \r\ncontract: \r\nFigure 13: A diagram of the agent as contractor lifecycle from Agentspace.\r\nContract execution\r\nThis requires the contractor runtime to be able to fulfill the contracts and solve the \r\ntasks behind contracts according to their defined specifications. Prioritizing quality and \r\ncompleteness over latency enables to fully leverage the capabilities of LLMs, for example \nAgents Companion\r\nFebruary 2025 50\r\nby generating different solutions, and reviewing, scoring, and evolving them. An example of \r\nthis methodology is shown below in the Co-Scientist study. The engine can iterate and self\u0002validate the results and deliverables based on the provided expectations, and can improve \r\nand self-correct until the validators are fulfilled. The ability to concretely validate a solution \r\nagainst a set of objective criterias has proven to work extremely well in the context of AI and \r\nhas been at the core of successful AI systems such as for example Alpha-Code.\r\nContract Negotiation\r\nOne core hypothesis behind contracts in the context of automation agents specifically is that \r\nmany tasks in the enterprise world can draw significant benefit from leveraging the power of \r\nLLMs when used in a less-constrained manner (latency and cost wise).\r\nBeing able to tackle more and more complex tasks and making it possible for customers to \r\nbe able to rely on and trust the results of contractors will ensure real value for companies. \r\nEven that being said, we need to have a notion of relative priority in order to make sure that \r\ntasks are appropriately prioritized as well as resources fairly allocated. We thus introduce a \r\nnotion of cost (typically relative per customer or contract initiator) which can be discussed \r\nand negotiated between the contract initiator and the contractor, in order to make sure that \r\nthe contract receives the adequate resources relative to the other contracts initiated by the \r\ncontract initiator. The contractors can also negotiate other aspects of the contracts, for \r\nexample in terms of specification and deliverables (cf. also section below on feedback).\nAgents Companion\r\nFebruary 2025 51\r\nContract Feedback\r\nContracts give a vehicle to provide feedback and in particular resolve ambiguities. As tasks \r\nbecome more and more complex, it is critical to be able to raise ambiguities or other issues \r\nrelated to the tasks specifications as early as possible. Contractors can give feedback on the \r\ncontract just after having received the contract (initial contract assessment), and then at a \r\nfrequency predefined in the contract.\r\nThis feedback will contain clarification requests, or other types of feedback about the \r\nunderspecification or misspecification of tasks (inconsistencies, conflicting specs, \r\nclarification, etc.).\r\nSubcontracts\r\nAlthough not part of the contract definition and specification directly, the ability to \r\ndecompose a task into subtasks by generating subcontracts is a core concept that will be \r\nused to power the contractors‚Äô engine.\r\nWhen a task is considered too complex to be tackled directly, contractors can decide to \r\ndecompose the task into smaller and easier tasks, which will be added to the execution \r\nqueue for solving. This is made possible only through the contract formalization described \r\nabove, which makes it possible for the contractors to generate, process and manipulate \r\nother contracts in a uniform and standardized way.\nAgents Companion\r\nFebruary 2025 52\r\nGoogle's Co-Scientist: A Case Study in \r\nMulti-Agent Intelligence\r\nGoogle's AI co-scientist is a prime example of a multi-agent LLM system applied to scientific \r\nresearch. This system utilizes a team of specialized agents, each with its own role and \r\nexpertise, to accelerate the pace of scientific discovery. These agents collaborate to \r\ngenerate, evaluate, and refine hypotheses, mirroring the iterative process of scientific inquiry.\r\nThe co-scientist system employs a \"generate, debate, and evolve\" approach, drawing \r\ninspiration from the scientific method. This approach involves generating diverse hypotheses, \r\ncritically evaluating their potential, and refining them through ongoing feedback and analysis. \r\nThe system leverages the strengths of different LLMs, each specializing in a particular aspect \r\nof the research process, to achieve a more comprehensive and robust outcome.\r\nFor instance, in a study on liver fibrosis treatments, the co-scientist not only identified \r\nexisting drugs but also proposed new mechanisms and promising drug candidates, \r\ndemonstrating its potential to generate novel insights. Some of its major components are: \r\n‚Ä¢ Data Processing Agents: aggregate and structure large volumes of experimental data.\r\n‚Ä¢ Hypothesis Generators: propose potential explanations based on existing research and \r\nnew findings.\r\n‚Ä¢ Validation Agents: run simulations and verify results before presenting them \r\nto researchers.\r\n‚Ä¢ Collaboration Agents: communicate findings across different research teams, enhancing \r\ninterdisciplinary cooperation.\nAgents Companion\r\nFebruary 2025 53\r\nFigure 14: A process diagram of the AI co-scientist system31\r\nThis approach exemplifies how multi-agent architectures move beyond static AI interactions, \r\ninstead fostering dynamic, evolving intelligence capable of handling sophisticated tasks in \r\nresearch, enterprise automation, and knowledge management.\nAgents Companion\r\nFebruary 2025 54\r\nAutomotive AI: Real World Use of \r\nMulti-Agent Architecture\r\nTo illustrate how multi-agent concepts manifest in practice, let's examine a comprehensive \r\nmulti-agent system designed for automotive conversational AI, where several specialized \r\nagents collaborate to provide an intuitive and seamless in-car experience.\r\nFirst, we‚Äôll look at some examples of specialized agents, followed by some common patterns \r\nfor combining them to form a multi-agent system.\r\nSpecialized Agents\r\nLet‚Äôs first look at some examples of specialized agents. \r\nConversational Navigation Agent\r\nThe Conversational Navigation Agent is specialized in helping users find locations, suggest \r\nplaces, and navigate using APIs like Google Places and Maps. This agent understands \r\nnavigation intents like \"Find me a sushi restaurant nearby,\" queries the Places API for relevant \r\nresults, re-ranks these results based on user preferences and historical data, and sends \r\nnavigation commands to the car's built-in system.\nAgents Companion\r\nFebruary 2025 55\r\nExample Interaction:\r\nUser: \"I need to take a break for lunch. What are good restaurants on my route \r\nto Munich?\"\r\nNavigation Agent: \"I found three well-rated restaurants along your route on the A9. In 25 \r\nkilometers, there's 'Gasthaus Alte M√ºhle' at the Ingolstadt exit with 4.5 stars - reviewers \r\npraise their traditional Bavarian dishes and beer garden. In 45 kilometers, 'La Strada' at \r\nthe service area has 4.1 stars with good reviews for quick Italian meals. Or if you can wait \r\n70 kilometers, 'Zeitlos' near Allershausen has 4.7 stars - it's a bit fancier with farm-to-table \r\ncuisine. Which one interests you most?\"\r\nUser: \"The Bavarian place sounds good. Is there convenient parking there, and how far is \r\nit from the motorway?\"\r\nNavigation Agent: \"Gasthaus Alte M√ºhle has a dedicated parking area with about 40 \r\nspaces. It's only 1.2 kilometers from the A9 exit at Ingolstadt-Nord - about a 2-minute drive. \r\nThey're known for their Schweinebraten and homemade dumplings. It gets busy around \r\nnoon, but it's currently showing moderate occupancy. Would you like me to set this as your \r\ndestination and guide you there? You'll arrive around 12:15 if we head there now.\"\r\nUser: \"The Bavarian place sounds good. Is there convenient parking there, and how far is \r\nit from the motorway?\"\r\nNavigation Agent: \"Gasthaus Alte M√ºhle has a dedicated parking area with about 40 \r\nspaces. It's only 1.2 kilometers from the A9 exit at Ingolstadt-Nord - about a 2-minute drive. \r\nThey're known for their Schweinebraten and homemade dumplings. It gets busy around \r\nnoon, but it's currently showing moderate occupancy. Would you like me to set this as your \r\ndestination and guide you there? You'll arrive around 12:15 if we head there now.\"\nAgents Companion\r\nFebruary 2025 56\r\nConversational Media Search Agent\r\nThe Conversational Media Search Agent is specialized in helping users find and play music, \r\naudiobooks, and podcasts. This agent retrieves media from local databases or streaming \r\nservices, uses web search for additional content when necessary, suggests media based on \r\ncontextual factors like mood, weather, and time of day, and handles voice commands such \r\nas \"Play a relaxing playlist for my drive.\" It also identifies similar artists or content when users \r\nask questions like \"Who sounds like John Coltrane?\"\r\nExample Interaction:\r\nUser: \"Play something upbeat to help me stay alert on this long motorway drive.\"\r\nMedia Search Agent: \"I'll play an upbeat driving playlist to help keep you energized. \r\nStarting with 'Don't Stop Me Now' by Queen, followed by some Daft Punk and Stromae \r\ntracks. I've added some popular European radio hits that match your preferences. I've \r\nadjusted the volume for optimal road awareness. Just say 'next' if you want to skip \r\na song.\"\r\nMessage Composition Agent\r\nThe Message Composition Agent is specialized in helping users draft, summarize, and send \r\nmessages or emails while driving. This agent parses voice commands like \"Tell Alex I'm \r\nrunning late,\" uses natural language models to compose contextually appropriate messages, \r\noffers draft previews with user modification options, and integrates with various messaging \r\napps including SMS, WhatsApp, and email.\nAgents Companion\r\nFebruary 2025 57\r\nExample Interaction:\r\nUser: \"There's heavy traffic on the E40. Let my team know I'll be 20 minutes late to the \r\nmorning standup.\"\r\nMedia Search Agent: \"I've prepared a message to your work team: 'Stuck in traffic on \r\nthe E40. Will be about 20 minutes late to our morning standup. Please start without me.' \r\nShould I send this to your 'Work Team' chat group, or would you like to edit it first?\"\r\nCar Manual Agent\r\nThe Car Manual Agent is specialized in providing answers to car-related questions by \r\nleveraging a Retrieval-Augmented Generation (RAG) system. This agent retrieves relevant \r\nsections from the car manual based on user queries, summarizes and contextualizes this \r\ninformation using an LLM, and links users to detailed documentation or instructional videos \r\nwhen appropriate.\r\nExample Interaction:\r\nUser: \"How do I turn off the lane-keeping assist feature in this Volkswagen?\"\r\nMedia Search Agent: \"To turn off lane-keeping assist in your Volkswagen, press the \r\nbutton with the car-and-lane icon located on the left side of your steering wheel. You'll \r\nsee a confirmation in the driver display when it's deactivated. You can also disable \r\nit permanently in the infotainment system under Settings > Driver Assistance > Lane \r\nKeeping. Would you like me to walk you through the settings menu instead?\"\nAgents Companion\r\nFebruary 2025 58\r\nGeneral Knowledge Agent\r\nThe General Knowledge Agent is specialized in answering factual questions about the world, \r\nhistory, science, culture, and other general topics. This agent accesses a broad knowledge \r\nbase to answer factual questions, provides biographical information about people, offers \r\ncontextual explanations of concepts and phenomena, maintains grounding in factual \r\ninformation while avoiding hallucinations, and responds to follow-up questions by maintaining \r\ncontextual awareness.\r\nExample Interaction:\r\nUser: \"Tell me an interesting fact about Salzburg.\"\r\nMedia Search Agent: \"Salzburg, Austria is the birthplace of Mozart, one of history's most \r\nfamous composers. Beyond that well-known fact, Salzburg's old town is a UNESCO World \r\nHeritage site, and parts of the beloved musical 'The Sound of Music' were filmed there in \r\n1964. The Salzburg Festival, one of the world's most prestigious music and drama festivals, \r\nhas been held there annually since 1920.\"\r\nPatterns in Use\r\nLet‚Äôs look at the some common ways used to combine these agents.\r\nHierarchical Pattern\r\nA central Orchestrator Agent classifies queries and routes them to specialized agents. For \r\nexample, when a user asks \"Find me a sushi restaurant nearby,\" the Orchestrator detects \r\nthis as a navigation request and routes it to the Navigation Agent, which handles location \r\nsearches and interaction with maps APIs.\nAgents Companion\r\nFebruary 2025 59\r\nFigure 15. Hierarchical pattern.\r\nThe Orchestrator Agent is specialized in routing queries to the most appropriate specialized \r\nagents and managing the overall conversation flow. This agent analyzes user queries to \r\ndetermine domain and intent, directs requests to the most suitable specialized agent, \r\nmaintains conversation context across multiple turns, and manages fallback strategies when \r\nspecialized agents cannot provide satisfactory responses.\r\nExample Interaction:\r\nFirst Turn:\r\nUser: \"Is there a service area ahead with clean toilets?\"\r\nOrchestrator Agent: [internally routes to Navigation Agent]\r\nNavigation Agent: \"There's a service area 20 kilometers ahead on the E19. It's Aire \r\nde Waremme, which was renovated last year and has good ratings for facilities and \r\ncleanliness. It also has a Paul bakery and a quick-service restaurant.\"\r\nSecond Turn:\nAgents Companion\r\nFebruary 2025 60\r\nUser: \"Will it rain at my destination this evening?\"\r\nOrchestrator Agent: [recognizes weather query and routes to Weather \r\nInformation Agent]\r\nWeather Information Agent: \"At your destination in Brussels, the forecast shows a 60% \r\nchance of light rain in the evening, starting around 19:00. Temperatures will be around \r\n14¬∞C. I'd recommend bringing an umbrella if you plan to be outdoors.\"\r\nDiamond Pattern\r\nIn this variation of the hierarchical pattern, responses from specialized agents pass \r\nthrough a central moderation agent before reaching the user. For instance, the Navigation \r\nAgent generates a factual response about a nearby restaurant, which then goes through \r\na Rephraser Agent that adjusts the tone and style based on user preferences before \r\ntext-to-speech synthesis.\r\nThe Rephraser Agent is specialized in adapting the tone, style, and presentation of responses \r\nto match user preferences and context. This agent transforms technical information into \r\nconversational language, adjusts response length based on driving conditions and urgency, \r\npersonalizes communication style to match user preferences, and formats complex \r\ninformation for easier comprehension while driving.\r\nExample Interaction:\r\n[Raw response from Car Manual Agent before rephrasing]: \"In the event of a tyre \r\npressure monitoring system alert, the vehicle has detected that one or more tyres have \r\nfallen below the recommended inflation pressure of 2.2 bar. The affected tyre's pressure is \r\napproximately 1.8 bar, which is 18.75% below recommended levels. This does not constitute \r\nan immediate safety hazard, but prolonged driving with underinflated tyres can lead to \nAgents Companion\r\nFebruary 2025 61\r\ndecreased fuel efficiency, reduced tyre longevity, and potentially compromised handling \r\ncharacteristics. It is advisable to proceed to a service station at your earliest convenience \r\nto reinflate the tyre to proper specifications.\"\r\nRephraser Agent: [Adapts for driving context, adjusts information density and urgency]\r\nFinal Response to User: \"Your front right tyre is a bit low - down to 1.8 bar. It's safe to \r\nkeep driving, but you'll want to add some air at the next petrol station. Low tyre pressure \r\ncan affect your fuel economy and make the tyre wear out faster. I can help you find a \r\nnearby place to fill up if you'd like.\"\r\nFigure 16. Diamond pattern.\nAgents Companion\r\nFebruary 2025 62\r\nExample transformation:\r\nInitial Response (factual & neutral): \"I found a highly-rated sushi restaurant nearby. It's \r\ncalled Sakura Sushi, located at 123 Main Street. It has a 4.7-star rating and is open until 10 \r\nPM. Would you like me to start navigation?\"\r\nAfter rephrasing (playful style): \"Sushi craving? Say no more! Head over to Sakura Sushi \r\nat 123 Main Street, where the fish is fresh and the soy sauce flows freely! Rated 4.7 stars, \r\nopen till 10 PM. Ready for an umami adventure?‚Äù\r\nPeer-to-Peer\r\nAgents can hand off queries to one another when they detect that the orchestration \r\nmade a routing mistake. This creates a more resilient system that can recover from \r\ninitial misclassifications.\r\nFigure 17. Peer-to-peer.\nAgents Companion\r\nFebruary 2025 63\r\nExample scenario:\r\n1. User asks: \"Find a place to eat sushi nearby\"\r\n2. The Orchestrator correctly routes this to the Conversational Navigation Agent, which \r\nprovides information about nearby sushi restaurants.\r\n3. User follows up: \"How big is New York's Central Park?\"\r\n4. The Orchestrator might initially route this to the Conversational Navigation Agent again \r\n(based on the previous navigation-related conversation).\r\n5. However, the Conversational Navigation Agent recognizes this as a general knowledge \r\nquestion rather than a navigation request, and hands it off to the General Knowledge \r\nAgent, which can provide factual information about Central Park's size.\r\nAdvantages of peer-to-peer hand-off compared to centralized orchestration:\r\n1. Resilience to misclassification: Even if the central orchestrator makes an error in \r\nrouting, specialized agents can recognize when a query falls outside their domain and \r\nredirect appropriately.\r\n2. Domain expertise in routing: Specialized agents often have better understanding of the \r\nboundaries of their own domains. The Media Search Agent knows exactly what kinds of \r\nmusic-related queries it can handle better than a general orchestrator would.\r\n3. Reduced orchestration complexity: The central orchestrator doesn't need perfect \r\naccuracy in initial routing, reducing the complexity of its decision-making logic.\nAgents Companion\r\nFebruary 2025 64\r\nCollaborative Pattern\r\nThe Collaborative Pattern involves multiple agents working on complementary aspects of \r\nthe same task, with a Response Mixer Agent that combines elements from different agent \r\nresponses to create a comprehensive answer. This approach recognizes that different agents \r\ncontribute valuable pieces to a complete solution based on their specialized expertise. The \r\npattern is particularly valuable when:\r\n1. Different aspects of a query require different types of expertise (e.g., technical \r\nspecifications, practical advice, and conceptual explanations)\r\n2. No single agent has complete information to fully address the user's needs\r\n3. The user would benefit from multiple perspectives on the same question\r\n4. Different specialized agents have access to distinct knowledge bases or \r\nreasoning capabilities\r\nUnlike the competitive approach where responses compete, the collaborative pattern \r\nassumes that responses from different agents are complementary rather than redundant. \r\nThe Response Mixer Agent identifies the most valuable information from each source and \r\nsynthesizes it into a cohesive answer that leverages the unique strengths of each specialist.\r\nFor example, when asked about handling hydroplaning, the Car Manual Agent contributes \r\nvehicle-specific safety system information, the Driving Tips Agent provides practical driving \r\ntechniques, and the General Knowledge Agent explains the physics behind the phenomenon. \r\nTogether, they create a more complete and useful response than any single agent could \r\nprovide alone.\nAgents Companion\r\nFebruary 2025 65\r\nFigure 18. Collaborative pattern.\nAgents Companion\r\nFebruary 2025 66\r\nResponse Mixer Agent\r\nThe Response Mixer is specialized in picking the best responses from multiple agents \r\nand merging them when needed. This agent evaluates answers based on their accuracy \r\nand relevance, removes incorrect information, and combines useful parts from different \r\nresponses to create the most helpful answer for the user.\r\nExample Interaction:\r\nUser: \"How do I handle aquaplaning?\"\r\n[Behind the scenes, multiple agents generate responses:]\r\nCar Manual Agent Response: \"Your Audi is equipped with Electronic Stability Control \r\n(ESC) and Anti-lock Braking System (ABS) which help prevent aquaplaning by maintaining \r\ntraction control.\" [Confidence score: 71%]\r\nGeneral Knowledge Agent Response: \"Aquaplaning occurs when your tyres lose contact \r\nwith the road surface due to water buildup between the tyres and the road.\" [Confidence \r\nscore: 65%]\r\nSafety Tips Agent Response: \"If you experience aquaplaning, ease off the accelerator, \r\navoid sudden braking or steering, and gently steer in the direction you want to go until you \r\nregain traction.\" [Confidence score: 94%]\r\nResponse Mixer Agent: [Picks the most relevant parts and merges them into one \r\ncomplete answer]\r\nFinal Response to User: \"If you experience aquaplaning, which happens when your \r\ntyres lose contact with the road due to water buildup, ease off the accelerator, avoid \r\nsudden braking or steering, and gently steer in the direction you want to go until you \r\nregain traction. Your Audi's Electronic Stability Control and ABS systems will help maintain \r\ncontrol, but proper driving technique is still essential.\"\nAgents Companion\r\nFebruary 2025 67\r\nThis competitive approach ensures that critical safety information isn't missed due to \r\nmisrouting, and the user receives the most helpful possible response even when their query \r\nhas multiple valid interpretations.\r\nAdaptive Loop Pattern\r\nThe Adaptive Loop Pattern involves iterative refinement through repeated attempts, \r\nprogressively improving results until they meet desired criteria.\r\nThe Conversational Navigation Agent can implement a loop pattern to iteratively improve \r\nsearch results when initial queries don't yield satisfactory outcomes.\r\nExample Interaction:\r\n1. User asks: \"Find a nice Italian restaurant that serves vegan options\"\r\n2. The Navigation Agent queries Places API with these parameters\r\n3. The agent evaluates the results and finds no restaurants meeting all criteria\r\n4. Instead of returning \"no results,\" the agent automatically reformulates the query:\r\n‚Ä¢ First loop: Searches for \"Italian restaurants with vegetarian options\"\r\n‚Ä¢ Second loop: Broadens to \"Italian restaurants\" and then filters for those mentioning \r\nplant-based options\r\n‚Ä¢ Third loop: If still unsuccessful, searches for \"vegan restaurants\" and filters for \r\nItalian-influenced cuisine\r\n5. The agent presents the best matches from these progressive searches, explaining how \r\nthey relate to the original request\nAgents Companion\r\nFebruary 2025 68\r\nThis looping behavior enables more robust search capabilities that adapt to availability and \r\ncontext, providing useful results even when exact matches aren't available.\r\nAdvantages of Multi-Agent Architecture for Automotive AI\r\nMulti-agent systems bring powerful advantages to automotive AI by breaking down complex \r\ntasks into specialized roles. Think of it as assembling a team of experts rather than relying on \r\none generalist.\r\nIn this approach, each agent specializes in what it does best. The Navigation Agent focuses \r\nsolely on finding locations and planning routes. The Media Search Agent becomes an \r\nexpert in music and podcasts. The Car Manual Agent specializes in vehicle features and \r\ntroubleshooting. By focusing on specific domains, each agent develops deeper capabilities in \r\nits area.\r\nThis specialization makes the entire system more efficient. When an agent handles a \r\nnarrower set of tasks, it becomes simpler to optimize its performance. The result is higher \r\nquality responses delivered more quickly and at lower computational cost. Performance \r\nimproves because the system can match the right resources to each task. Simple requests \r\nuse minimal processing power, while complex questions tap into more powerful resources \r\nonly when needed.\r\nSpeed matters in a vehicle, and multi-agent systems deliver where it counts. Critical \r\nfunctions like adjusting climate controls or opening windows run on fast, on-device \r\nagents for immediate response. Meanwhile, less urgent tasks like finding restaurant \r\nrecommendationscan use cloud-based agents with more extensive knowledge. This \r\nseparation ensures that essential vehicle controls remain responsive regardless of what else \r\nthe system is doing.\nAgents Companion\r\nFebruary 2025 69\r\nThis design also creates natural resilience. If internet connectivity drops the essential \r\nfunctions running on on-device agents continue working. You might temporarily lose \r\nrestaurant recommendations, but climate control and basic media playbacks still \r\nfunction perfectly.\r\nAgent Builder\r\nVertex AI Agent Builder is a collection of products and services for developers. We have \r\nput together a comprehensive platform for you to build and connect agents. The engineering \r\nexcellence and security from Google Cloud, the AI research from Google Deepmind, and the \r\nbest practices of Agent Ops. Google Cloud is building our own agents on top of this platform, \r\nand now you can too. Expect many more exciting announcements 2025 targeting developers \r\nof agents.\r\nVertex AI Agent Engine streamlines development, relying on Google engineering managed \r\nintegrations with popular open source agent libraries. It provides a managed autoscaling \r\nruntime and many services agents will need (eg: session, examples, trace, evals). This is the \r\nvery low effort and high value way to safely deploy agents you have written in any framework.\r\nVertex AI Eval Service provides all of the evaluation tools discussed in this whitepaper, and \r\nmore. LLMs, RAG, and Agent evals are stable and scalable via the Vertex AI Eval Service, with \r\nconvenient integrations into monitoring and experimentation offerings.\r\nA large portfolio of agent tools, with more to watch out for:\r\n‚Ä¢ Retrieval via Vertex AI Search26 or RAG Engine28.\r\n‚Ä¢ Non-search based retrieval from DBs via Gen AI Toolbox for Databases32\nAgents Companion\r\nFebruary 2025 70\r\n‚Ä¢ Application integrations33 with hundreds of APIs supporting full ACLs\r\n‚Ä¢ Turn any API into a managed, enterprise ready tool with Apigee Hub34\r\nAnd of course the best LLMs for agents, with access to Vertex AI Model Garden35 and also \r\nthe Gemini family of models36 which will power the agentic era.\r\nSummary\r\nThis whitepaper (a companion to our earlier whitepaper on Agents) has explored the rapidly \r\nevolving landscape of generative AI agents, from their fundamental architecture to advanced \r\nevaluation techniques and the transformative potential of multi-agent systems. \r\nKey Takeaways for Developers:\r\n1. Agent Ops is Essential: Building successful agents goes far beyond the initial proof\u0002of-concept. Embrace Agent Ops principles, integrating best practices from DevOps and \r\nMLOps, but also focusing on agent-specific elements like tool management, orchestration, \r\nmemory, and task decomposition.\r\n2. Metrics Drive Improvement: Start with business-level KPIs (like goal completion, user \r\nengagement, or revenue) as your \"north star.\" Then, instrument your agents to track \r\ngranular metrics related to critical tasks, user interactions, and agent actions (traces). \r\nHuman feedback (üëç,  user  surveys)  is  inv\r\n3. Automated Evaluation is Key: Don't rely solely on manual testing. Implement automated \r\nevaluation frameworks that assess agent capabilities, trajectory (the steps taken), and the \r\nfinal response. Leverage techniques like exact match, in-order match, precision/recall for \r\ntrajectory evaluation, and autoraters (LLMs as judges) for final response quality.\nAgents Companion\r\nFebruary 2025 71\r\n4. Human-in-the-Loop is Crucial: Automated metrics are powerful, but human evaluation \r\nprovides essential context, especially for subjective aspects like creativity, common sense, \r\nand nuance. Use human feedback to calibrate and validate your automated evaluation \r\nmethods. Don‚Äôt outsource the domain knowledge.\r\n5. Multi-Agent Systems Offer Advantages: Consider multi-agent architectures for \r\ncomplex tasks. They can improve accuracy, efficiency, scalability, and fault tolerance. \r\nUnderstand different design patterns (sequential, hierarchical, collaborative, competitive) \r\nand choose the right one for your application.\r\n6. Agentic RAG Improves Relevance: Move beyond traditional RAG by incorporating \r\nagents that actively refine search queries, evaluate retrieved information, and adapt to \r\nevolving knowledge. This leads to more accurate and contextually relevant responses.\r\n7. Search Optimization is Foundational to RAG: Before diving into complex agentic RAG, \r\noptimize your underlying search engine. Techniques like semantic chunking, metadata \r\nenrichment, fine-tuning embedding models, and using rankers can significantly improve \r\nretrieval quality.\r\n8. Agent and Tool Registries are Important: As the number of Agents or Tools you \r\nare using grow, a registry to manage the capabilities, ontology, and performance \r\nbecomes essential.\r\n9. Security is Paramount: When deploying agents, especially within an enterprise, prioritize \r\nsecurity. Leverage platforms like Google Agentspace that offer built-in security features \r\nlike RBAC, VPC Service Controls, and IAM integration.\r\n10.Efficient use of developer cycles: The classic build vs buy design choices remain front \r\nof mind, as the industry of gen AI agents is rapidly evolving. Consider platforms and \r\nproducts as alternatives to building everything from scratch. This will buffer some of the \r\nchurn of a fast changing industry and allow you to focus on your data, domain, and users.\nAgents Companion\r\nFebruary 2025 72\r\n11. Agents in the enterprise: Agents are transforming the way we work by making us much \r\nmore productinve, and the way automation can be accomplished. Knowledge workers will \r\nincreasingly be managing fleets of agents and novel UX will emerge. Google Agentspace \r\nis a powerful tool allowing to put Enterprise Search, AI and AI Agents on top of company‚Äôs \r\ndata and workflows\r\nFuture Directions for Agent Research and Development: The field of AI agents is \r\nundergoing rapid evolution. Key areas of ongoing research and development include:\r\n‚Ä¢ Advanced Evaluation Methods: Developing more robust and scalable evaluation \r\ntechniques, including process-based evaluation (focusing on reasoning), AI-assisted \r\nevaluation, and standardized benchmarks.\r\n‚Ä¢ Multi-Agent Coordination: Improving the coordination and communication mechanisms \r\nwithin multi-agent systems to enable more effective collaboration, task handling, \r\nand reasoning.\r\n‚Ä¢ Real-World Adaptation: Creating agents that can adapt and learn in dynamic, \r\nunpredictable real-world environments. Production systems like automotive AI \r\nillustrate how agents must balance between on-device performance for critical \r\nfunctions and cloud-based capabilities for complex tasks, often adapting to changing \r\nconnectivity conditions.\r\n‚Ä¢ Explainability and Interpretability: Making agent behavior more transparent and \r\nunderstandable, allowing developers and users to gain deeper insights into their \r\ndecision-making processes.\r\n‚Ä¢ Long-Term Memory and Learning: Developing more sophisticated memory mechanisms \r\nthat allow agents to retain and utilize information over extended periods, enabling \r\ncontinuous learning and adaptation.\nAgents Companion\r\nFebruary 2025 73\r\n‚Ä¢ Agent Communication Protocols: Better defining how agents share tasks, knowledge, \r\nand messages, especially across remote systems which are opaque.\r\n‚Ä¢ From Agents to contractors: In order for agents to get to next level of reliability and \r\nutility, we will need to step up the definition of tasks, making them into contracts with clear \r\ndeliverables, validation mechanisms, and ability to negotiate ambiguities, similarly to how \r\nwe contract work from other companies.\r\nCall to Action:\r\nThe future of AI is agentic. We encourage developers to embrace these concepts and \r\nbegin building the next generation of intelligent applications. Start experimenting with the \r\ntools and techniques discussed in this whitepaper. Explore the resources available, such \r\nas Google Agentspace, NotebookLM Enterprise, Vertex Eval Service, Cloud Observability, \r\nand Vertex AI Search, to accelerate your development process. Dive into the provided code \r\nexamples, tutorials, and documentation to gain hands-on experience. Build, evaluate, iterate, \r\nand contribute to the growing community of agent developers. The possibilities are limitless, \r\nand the time to build is now! Specifically, get started with the code and Colab notebooks in \r\nthe references.\nAgents Companion\r\nFebruary 2025 74\r\nEndnotes\r\n1. Shafran, I., Cao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'. \r\nAvailable at: https://arxiv.org/abs/2210.03629.\r\n2. Wei, J., Wang, X. et al., 2023, 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models'. \r\nAvailable at: https://arxiv.org/pdf/2201.11903.pdf.\r\n3. Wang, X. et al., 2022, 'Self-Consistency Improves Chain of Thought Reasoning in Language Models'. \r\nAvailable at: https://arxiv.org/abs/2203.11171.\r\n4. Diao, S. et al., 2023, 'Active Prompting with Chain-of-Thought for Large Language Models'. \r\nAvailable at: https://arxiv.org/pdf/2302.12246.pdf.\r\n5. Zhang, H. et al., 2023, 'Multimodal Chain-of-Thought Reasoning in Language Models'. \r\nAvailable at: https://arxiv.org/abs/2302.00923.\r\n6. Yao, S. et al., 2023, 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models'. \r\nAvailable at: https://arxiv.org/abs/2305.10601.\r\n7. Long, X., 2023, 'Large Language Model Guided Tree-of-Thought'. \r\nAvailable at: https://arxiv.org/abs/2305.08291.\r\n8. Google. ';Google Gemini Application'. Available at: http://gemini.google.com.\r\n9. Swagger. 'OpenAPI Specification'. Available at: https://swagger.io/specification/.\r\n10. Xie, M., 2022, 'How does in-context learning work? A framework for understanding the differences \r\nfromtraditional supervised learning'. Available at: https://ai.stanford.edu/blog/understanding-incontext/.\r\n11. Google Research. 'ScaNN (Scalable Nearest Neighbors)'. \r\nAvailable at: https://github.com/google-research/google-research/tree/master/scann.\r\n12. LangChain. 'LangChain'. Available at: https://python.langchain.com/v0.2/docs/introduction/.\r\n13. Sokratis Kartakis, 2024, ‚ÄòGenAI in Production: MLOps or GenAIOps?‚Äô. Available \r\nat: https://medium.com/google-cloud/genai-in-production-mlops-or-genaiops-25691c9becd0.\r\n14. Sokratis Kartakis, 2024 ‚ÄòGen AI Ops, Operationalize Generative AI, A practical Guide‚Äô. Available at:\r\nhttps://medium.com/google-cloud/genaiops-operationalize-generative-ai-a-practical\u0002guide-d5bedaa59d78.\nAgents Companion\r\nFebruary 2025 75\r\n15. Cloud Trace overview. Available at: https://cloud.google.com/trace/docs/overview.\r\n16. Berkeley Function-Calling Leaderboard (BFCL). Available at:\r\nhttps://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html.\r\n17. Karthik Narasimhan, et al. 2024, ‚ÄòœÑ-bench‚Äô. Available at https://arxiv.org/abs/2406.12045.\r\n18. Karthik Valmeekam, et al., 2023, ‚ÄòPlanBench‚Äô. Available at: https://arxiv.org/abs/2206.10498.\r\n19. Xiao Liu, et al., 2023, ‚ÄòAgentBench‚Äô. Available at: https://arxiv.org/abs/2308.03688.\r\n20. Martin Iglesias, et al., 2025, `DBAStep` Available at: https://huggingface.co/spaces/adyen/DABstep.\r\n21. LangSmith platform for agent observability. \r\nAvailable at: https://docs.smith.langchain.com/evaluation/concepts#agents.\r\n22. Mingchen Zhuge, et al., 2024, ‚ÄòAgent-as-a-Judge: Evaluate Agents with Agents‚Äô. \r\nAvailable at: https://arxiv.org/abs/2410.10934.\r\n23. Multi-agent documentation from LangGraph. \r\nAvailable at: https://langchain-ai.github.io/langgraph/concepts/multi_agent/.\r\n24. LangChain blog 2024, ‚ÄòMulti-agent workflows‚Äô. \r\nAvailable at: https://blog.langchain.dev/langgraph-multi-agent-workflows/.\r\n25. Vectorize blog 2024, ‚ÄòHow I finally got agentic RAG to work right‚Äô. \r\nAvailable at: https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/.\r\n26. Vertex AI Search, product documentation. Available at: https://cloud.google.com/enterprise-search.\r\n27. Vertex AI Search Builder APIs, product documentation. \r\nAvailable at: https://cloud.google.com/generative-ai-app-builder/docs/builder-apis.\r\n28. Vertex AI RAG Engine, product documentation. \r\nAvailable at: https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview.\r\n29. Agentspace product documentation. \r\nAvailable at: https://cloud.google.com/agentspace/agentspace-enterprise/docs/overview.\r\n30. NotebookLM Enterprise product documentation. \r\nAvailable at: https://cloud.google.com/agentspace/notebooklm-enterprise/docs/overview.\nAgents Companion\r\nFebruary 2025 76\r\n31. Juraj Gottweis, et. al., 2025, ‚ÄòAccelerating scientific breakthroughs with an AI co-scientist‚Äô. Available at: \r\nhttps://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/.\r\n32. Hamsa Buvaraghan, et al. 2025, ‚ÄòAnnouncing public beta of Gen AI Toolbox for Databases‚Äô. Available at:\r\nhttps://cloud.google.com/blog/products/ai-machine-learning/announcing-gen-ai-toolbox\r\n-for-databases-get-started-today?e=48754805.\r\n33. Google Cloud Integration Connectors, product documentation. \r\nAvailable at: https://cloud.google.com/integration-connectors/docs.\r\n34. Apigee API Hub, product documentation. \r\nAvailable at: https://cloud.google.com/apigee/docs/apihub/what-is-api-hub.\r\n35. Vertex AI Model Garden, product documentation. \r\nAvailable at: https://cloud.google.com/model-garden.\r\n36. Gemini family of LLMs, product documentation. \r\nAvailable at: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models.\r\n37. Get Started Evaluating Agents with the Vertex Eval Service. Available at:\r\nhttps://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-agents.\r\n38. Irina Sigler, Ivan Nardini. Jan 2025 ‚ÄòIntroducing Agent Evaluation in Vertex AI‚Äô. Available at:\r\nhttps://cloud.google.com/blog/products/ai-machine-learning/introducing-agent-evaluation-in-vertex\r\n-ai-gen-ai-evaluation-service?e=48754805.\r\n39. Review sample agent evaluation notebooks for LangGraph, CrewAI, and LangChain. \r\nAvailable at: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/.\r\n40. Review many sample agents, primarily beginner and intermediate level. \r\nAvailable at: https://github.com/GoogleCloudPlatform/generative-ai/.\r\n41. Review many sample agents, intermediate and advanced levels. \r\nAvailable at: https://github.com/GoogleCloudPlatform/applied-ai-engineering-samples.\n",
  "token_count": 19823
}
